{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4462e241",
   "metadata": {},
   "source": [
    "# Week 1 Assignment: ARIMA Time Series Forecasting\n",
    "\n",
    "**Contents:**\n",
    "- Data collection (Yahoo Finance)\n",
    "- Preprocessing & stationarity testing\n",
    "- Train/test split (80/20)\n",
    "- ADF-based selection of `d` (0 or 1)\n",
    "- Grid search (AIC) for best `(p, d, q)` on **training set only**\n",
    "- Forecasting and correct index alignment\n",
    "- Evaluation: MAE, MSE, RMSE\n",
    "- Residual analysis\n",
    "\n",
    "> This notebook is set up to avoid common pitfalls: no data leakage (models fit on training only), no double-differencing, and correct conversion to level forecasts when needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0d0c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements if you don't have them (uncomment to run)\n",
    "# !pip install yfinance statsmodels scikit-learn nbformat\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import yfinance as yf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "print('Libraries loaded')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaacd3b",
   "metadata": {},
   "source": [
    "## 1) Data Collection\n",
    "We download historical stock closing prices from Yahoo Finance. Change the `TICKER`, `START`, and `END` as required.\n",
    "\n",
    "For reproducibility in a classroom environment you can replace this with a local CSV file if internet access is restricted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4fd43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters - change these if you want\n",
    "TICKER = 'TSLA'   # e.g., 'TSLA', 'MSFT', 'GOOG'\n",
    "START = '2023-01-01'\n",
    "END = '2024-12-31'\n",
    "\n",
    "# Download data\n",
    "raw = yf.download(TICKER, start=START, end=END)\n",
    "raw = raw.sort_index()\n",
    "raw.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30bcac7",
   "metadata": {},
   "source": [
    "## 2) Preprocessing\n",
    "- Use only the `Close` price for forecasting.\n",
    "- Handle missing values by forward-fill.\n",
    "- (Optional) Resample if you prefer weekly/monthly data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121a9de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select closing price\n",
    "ts = raw['Close'].copy()\n",
    "\n",
    "# Check missing values\n",
    "print('Missing values before:', ts.isna().sum())\n",
    "\n",
    "# Forward-fill missing values\n",
    "ts = ts.fillna(method='ffill')\n",
    "print('Missing values after:', ts.isna().sum())\n",
    "\n",
    "# Simple plot\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(ts)\n",
    "plt.title(f'{TICKER} Close Price')\n",
    "plt.ylabel('Price')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2c6ea1",
   "metadata": {},
   "source": [
    "## 3) Stationarity Test (ADF) and choosing `d`\n",
    "We use the Augmented Dickey-Fuller (ADF) test to check stationarity. If the series is non-stationary (p-value >= 0.05) we set `d=1`; otherwise `d=0`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c2f6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADF test on full series (for info)\n",
    "adf_full = adfuller(ts.dropna())\n",
    "print('ADF statistic (full):', adf_full[0])\n",
    "print('p-value (full):', adf_full[1])\n",
    "\n",
    "# We'll split into train/test first and use train to decide d (preventing lookahead)\n",
    "\n",
    "# Train-test split index\n",
    "train_size = int(len(ts) * 0.8)\n",
    "train = ts.iloc[:train_size]\n",
    "test = ts.iloc[train_size:]\n",
    "\n",
    "print('\\nTrain length:', len(train), 'Test length:', len(test))\n",
    "\n",
    "# ADF on train\n",
    "adf_train = adfuller(train.dropna())\n",
    "print('ADF statistic (train):', adf_train[0])\n",
    "print('p-value (train):', adf_train[1])\n",
    "\n",
    "# Decide d based on train ADF p-value\n",
    "if adf_train[1] < 0.05:\n",
    "    d_decision = 0\n",
    "else:\n",
    "    d_decision = 1\n",
    "\n",
    "print('\\nSelected d =', d_decision, '(0 => stationary, 1 => needs first differencing)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdebe18",
   "metadata": {},
   "source": [
    "### ACF & PACF (visual guide to choose p and q)\n",
    "Plot ACF and PACF of the (possibly differenced) training series to get an idea of suitable `p` and `q` ranges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97ef8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create series to analyze for ACF/PACF depending on d\n",
    "if d_decision == 1:\n",
    "    train_for_ac = train.diff().dropna()\n",
    "else:\n",
    "    train_for_ac = train.copy()\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plot_acf(train_for_ac, ax=plt.gca(), lags=30)\n",
    "plt.title('ACF (train)')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plot_pacf(train_for_ac, ax=plt.gca(), lags=30, method='ywm')\n",
    "plt.title('PACF (train)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a0bf23",
   "metadata": {},
   "source": [
    "## 4) Grid Search on Training Set (AIC)\n",
    "We perform a grid search **on the training set only**. `d` is fixed to the value chosen via the ADF test on the training set. We search over small p and q ranges to avoid overfitting and convergence issues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65ec059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "p_range = range(0, 4)\n",
    "q_range = range(0, 4)\n",
    "\n",
    "best_aic = np.inf\n",
    "best_order = None\n",
    "best_model = None\n",
    "results = []\n",
    "\n",
    "for p, q in itertools.product(p_range, q_range):\n",
    "    order = (p, d_decision, q)\n",
    "    try:\n",
    "        model = ARIMA(train, order=order)\n",
    "        fit = model.fit()\n",
    "        aic = fit.aic\n",
    "        results.append((order, aic))\n",
    "        if aic < best_aic:\n",
    "            best_aic = aic\n",
    "            best_order = order\n",
    "            best_model = fit\n",
    "        print(f\"Tested ARIMA{order} - AIC: {aic:.2f}\")\n",
    "    except Exception as e:\n",
    "        # print('Failed for', order, '->', e)\n",
    "        continue\n",
    "\n",
    "print('\\nBest order:', best_order, 'with AIC =', best_aic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7b9fbc",
   "metadata": {},
   "source": [
    "### Best model summary\n",
    "The best model from grid search is retained as `best_model` (fitted on the training set). We print a summary for inspection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1480dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_model is not None:\n",
    "    print(best_model.summary())\n",
    "else:\n",
    "    print('No model was successfully fitted. Consider widening ranges or checking data.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a88815a",
   "metadata": {},
   "source": [
    "## 5) Forecasting\n",
    "We forecast for the length of the test set. Since `best_model` was trained on the original train series and d was set inside the ARIMA call, the `forecast()` call will produce level forecasts (not differences). We'll ensure the forecast is converted into a pandas Series with the same index as `test`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945440d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast steps = len(test)\n",
    "steps = len(test)\n",
    "\n",
    "if best_model is None:\n",
    "    raise RuntimeError('No fitted model available from grid search.')\n",
    "\n",
    "forecast = best_model.forecast(steps=steps)\n",
    "# Convert forecast into Series and align index\n",
    "forecast = pd.Series(forecast, index=test.index)\n",
    "\n",
    "# Plot train, test, forecast\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(train.index, train, label='Train')\n",
    "plt.plot(test.index, test, label='Test')\n",
    "plt.plot(forecast.index, forecast, label='Forecast')\n",
    "plt.legend()\n",
    "plt.title(f'ARIMA Forecast (order={best_order})')\n",
    "plt.show()\n",
    "\n",
    "# Show a small numeric preview\n",
    "pd.DataFrame({'test': test, 'forecast': forecast}).head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbe80ed",
   "metadata": {},
   "source": [
    "## 6) Evaluation\n",
    "Compute MAE, MSE, and RMSE on the test set. These metrics quantify forecast accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951245d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(test, forecast)\n",
    "mse = mean_squared_error(test, forecast)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f'MAE: {mae:.4f}')\n",
    "print(f'MSE: {mse:.4f}')\n",
    "print(f'RMSE: {rmse:.4f}')\n",
    "\n",
    "# Put results in a small table\n",
    "pd.DataFrame({'MAE':[mae], 'MSE':[mse], 'RMSE':[rmse]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5054b7fe",
   "metadata": {},
   "source": [
    "## 7) Residual Analysis\n",
    "Analyze residuals from the fitted model (on training data) and forecast errors on the test data.\n",
    "- Residuals (train): should resemble white noise\n",
    "- Forecast errors (test - forecast): check distribution and autocorrelation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d04f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals from training fit\n",
    "resid = best_model.resid\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(resid)\n",
    "plt.title('Training residuals')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "resid.plot(kind='kde')\n",
    "plt.title('Residual density')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Forecast errors on test\n",
    "errors = test - forecast\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(errors)\n",
    "plt.title('Forecast errors (test - forecast)')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "errors.plot(kind='kde')\n",
    "plt.title('Error density')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ACF of errors - should be close to zero\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "plot_acf(errors.dropna(), lags=20)\n",
    "plt.title('ACF of forecast errors')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6424e210",
   "metadata": {},
   "source": [
    "## Conclusion & Next Steps\n",
    "- The grid search finds the `(p,d,q)` that minimizes AIC **on the training set** to avoid data leakage.\n",
    "- Forecasts were produced for the test set only and evaluated with MAE/MSE/RMSE.\n",
    "\n",
    "**Possible improvements:**\n",
    "- Use walk-forward validation for more robust evaluation.\n",
    "- Consider SARIMA if seasonality exists.\n",
    "- Explore LSTM or Prophet for non-linear patterns.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
